apiVersion: apps/v1
kind: Deployment
metadata:
  name: text-inference
  labels:
    app: text-inference
spec:
  selector:
    matchLabels:
      app: text-inference
  replicas: 8
  template:
    metadata:
      name: text-inference
      labels:
        app: text-inference
    spec:
      containers:
        - name: text-generation-inference
          image: ghcr.io/huggingface/text-generation-inference:1.3
          resources:
            limits:
              nvidia.com/gpu: 1
            requests:
              cpu: "4"
              memory: 4Gi
              nvidia.com/gpu: 1
          command:
            - "text-generation-launcher"
            - "--model-id"
            - "mistralai/Mistral-7B-v0.1"
            - "--num-shard"
            - "1"
          ports:
            - containerPort: 80
              name: http
          #volumeMounts:
          #  - name: model
          #    mountPath: /data
          #  - name: shm
          #    mountPath: /dev/shm
          env:
            - name: HUGGING_FACE_HUB_TOKEN
              value: replace - me
      #volumes:
      #  - name: model
      #    hostPath:
      #    path: /mnt
      #    type: DirectoryOrCreate
      #  - name: shm
      #    emptyDir:
      #      medium: Memory
      #      sizeLimit: 1Gi
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      #restartPolicy: Never

---

apiVersion: v1
kind: Service
metadata:
  name: text-inference
spec:
  ports:
    - port: 80
      protocol: TCP
      targetPort: http
  selector:
    app: text-inference
  type: ClusterIP